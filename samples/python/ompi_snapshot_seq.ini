#
# Template MTT configuration file for MTT users who plan
# to test nightly OMPI tarballs.
#
# Sample usage:
#   edit this file replaccing REPLACE_ME's with appropriate user-specific values
#   cd $MTT_HOME
#   pyclient/pymtt.py --verbose samples/python/ompi_snapshot_seq.ini
#

[MTTDefaults]

#
# set to true to have MTT server treat as non-trial data
#
trial = false
scratch = REPLACE_ME_PATH_TO_SCRATCH_DIR
description = OpenMPI master
platform = REPLACE_ME
executor = sequential

[Profile:Installed]

#======================================================================
# Middleware construction phases - get the middleware, build, and
# install it. This isn't a required phase - if the purpose of this test
# is to simply stress the physical system, then one can skip this phase
#======================================================================

[ASIS MiddlewareGet:OMPIMaster]
plugin = OMPI_Snapshot
url =  https://download.open-mpi.org/nightly/open-mpi/master
version_file = REPLACE_ME_NAME_OF_VERSION_FILE
mpi_name = ompi-nightly-master

#----------------------------------------------------------------------

[MiddlewareBuild:OMPIMaster]
parent = MiddlewareGet:OMPIMaster
plugin = Autotools
configure_options = --enable-debug
make_options = -j 1

#======================================================================
# Test construction phases - get and build the tests that the
# target software will run.
#======================================================================

[ASIS TestGet:IBM]
parent = MiddlewareBuild:OMPIMaster
plugin = Git
url =  git@github.com:open-mpi/ompi-tests
#username = foobar
#pwfile = /Users/foobar/mttpasswd
subdir = ibm

#----------------------------------------------------------------------

[SKIP TestGet:Intel]
parent = MiddlewareBuild:OMPIMaster
plugin = Git
url =  git@github.com:open-mpi/ompi-tests
subdir = intel_tests

#======================================================================
# Test build phase
#======================================================================

[ASIS TestBuild:IBMInstalled]
parent = TestGet:IBM
merge_stdout_stderr = 1
stderr_save_lines = 100
middleware = MiddlewareBuild:OMPIMaster
autogen_cmd = ./autogen.sh
configure_options = CC=mpicc CXX=mpic++ F77=mpif77
make_options = -j 1

#======================================================================
# Define some default launcher execution parameters
#======================================================================

[LauncherDefaults:OMPI]
plugin = OpenMPI
command = mpirun
np = 2
#options = --verbose, --novm
skipped = 77
merge_stdout_stderr = 1
stdout_save_lines = 100
stderr_save_lines = 100

#
#======================================================================
# Test run phase - the executor will automatically change directory to
# the top directory where the tests were installed, so any search for
# executables will take place relative to that point
#======================================================================

[TestRun:IBMInstalledOMPI]
plugin = OpenMPI
parent = TestBuild:IBMInstalled
timeout = 600
test_dir = "collective, communicator, datatype, environment, group, info, io, onesided, pt2pt, random, topology"
#test_dir = "collective, communicator"
max_num_tests = 10

# Tests that are supposed to fail
fail_tests = abort final
fail_timeout = max_procs

#
# THREAD_MULTIPLE test will fail with the openib btl because it
# deactivates itself in the presence of THREAD_MULTIPLE.  So just skip
# it.  loop_child is the target for loop_spawn, so we don't need to
# run it (although it'll safely pass if you run it by itself).
skip_tests = init_thread_multiple comm_split_f

#======================================================================
# Reporter phase
#======================================================================

[Reporter: text file backup]
plugin = TextFile
filename = mttresults.txt
summary_footer =
detail_header  =
detail_footer  =
textwrap = 78

#----------------------------------------------------------------------

[Reporter: IU database]
plugin = IUDatabase
realm = OMPI
username = REPLACE_ME
password = REPLACE_ME
platform = REPLACE_ME
url = https://mtt.open-mpi.org/submit/cpy/api/

