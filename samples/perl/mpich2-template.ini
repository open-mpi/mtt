#
# Copyright (c) 2006-2009 Cisco Systems, Inc.  All rights reserved.
# Copyright (c) 2006-2007 Sun Microystems, Inc.  All rights reserved.
#

# Note that there are many items in this file that, while they are
# good for examples, may not work for random MTT users.  For example,
# the "ompi-tests" SVN repository that is used in the examples below
# is *not* a public repository (there's nothing really secret in this
# repository; it contains many publicly-available MPI tests and
# benchmarks, but we have never looked into the redistribution rights
# of these codes, so we keep the SVN repository "closed" to the
# general public and only use it internally in the Open MPI project).

#======================================================================
# Overall configuration
#======================================================================

[MTT]
# See ompi-core-template.ini for more information on this section.

#----------------------------------------------------------------------

[Lock]
# See ompi-core-template.ini for more information on this section.

#======================================================================
# MPI get phase
#======================================================================

[MPI get: mpich2]
mpi_details = MPICH2

module = Tarball
tarball_filename = /home/jsquyres/mpich2-1.0.5p4.tar.gz
tarball_version = 1.0.5p4

#======================================================================
# Install MPI phase
#======================================================================

[MPI install: MPICH2/GNU]
mpi_get = mpich2
save_stdout_on_success = 1
merge_stdout_stderr = 0
# Needed to launch in SLURM; adding this to LD_LIBRARY_PATH here
# propagates this all the way through the test run phases that use
# this MPI install, where the test executables will need to have this
# set.
prepend_path = LD_LIBRARY_PATH /opt/slurm/current/lib

module = MPICH2
mpich2_vpath_mode = none
mpich2_make_all_arguments =
mpich2_compiler_name = gnu
mpich2_compiler_version = &get_gcc_version()
mpich2_configure_arguments = "CFLAGS=-g -pipe"
# These are needed to launch through SLURM; adjust as appropriate.
mpich2_additional_wrapper_ldflags = -L/opt/slurm/current/lib
mpich2_additional_wrapper_libs = -lpmi

#======================================================================
# MPI run details
#======================================================================

[MPI Details: MPICH2]

# Launching through SLURM.  If you use mpdboot instead, you need to
# ensure that multiple mpd's on the same node don't conflict (or never
# happen).
exec = srun -n &test_np() &test_executable() &test_argv()

#======================================================================
# Test get phase
#======================================================================

[Test get: trivial]
module = Trivial

#----------------------------------------------------------------------

[Test get: intel]
module = SVN
svn_url = https://svn.open-mpi.org/svn/ompi-tests/trunk/intel_tests

#----------------------------------------------------------------------

[Test get: ibm]
module = SVN
svn_url = https://svn.open-mpi.org/svn/ompi-tests/trunk/ibm
svn_post_export = <<EOT
./autogen.sh
EOT

#----------------------------------------------------------------------

[Test get: onesided]
module = SVN
svn_url = https://svn.open-mpi.org/svn/ompi-tests/trunk/onesided
svn_post_export = <<EOT
./autogen.sh
EOT

#----------------------------------------------------------------------

[Test get: mpicxx]
module = SVN
svn_url = https://svn.open-mpi.org/svn/ompi-tests/trunk/cxx-test-suite
svn_post_export = <<EOT
./autogen.sh
EOT

#----------------------------------------------------------------------

[Test get: imb]
module = SVN
svn_url = https://svn.open-mpi.org/svn/ompi-tests/trunk/IMB_2.3

#----------------------------------------------------------------------

[Test get: netpipe]
module = SVN
svn_url = https://svn.open-mpi.org/svn/ompi-tests/trunk/NetPIPE_3.6.2

#======================================================================
# Test build phase
#======================================================================

[Test build: trivial]
test_get = trivial
save_stdout_on_success = 1
merge_stdout_stderr = 1

module = Trivial

#----------------------------------------------------------------------

[Test build: intel]
test_get = intel
save_stdout_on_success = 1
merge_stdout_stderr = 1

module = Intel_OMPI_Tests
intel_ompi_tests_buildfile = all_tests_no_perf

#----------------------------------------------------------------------

[Test build: ibm]
test_get = ibm
save_stdout_on_success = 1
merge_stdout_stderr = 1

module = Shell
shell_build_command = <<EOT
./configure CC=mpicc CXX=mpic++ F77=mpif77
make
EOT

#----------------------------------------------------------------------

[Test build: onesided]
test_get = onesided
save_stdout_on_success = 1
merge_stdout_stderr = 1
stderr_save_lines = 100

module = Shell
shell_build_command = <<EOT
./configure
make
EOT

#----------------------------------------------------------------------

[Test build: mpicxx]
test_get = mpicxx
save_stdout_on_success = 1
merge_stdout_stderr = 1

module = Shell
shell_build_command = <<EOT
./configure CC=mpicc CXX=mpic++
make
EOT

#----------------------------------------------------------------------

[Test build: imb]
test_get = imb
save_stdout_on_success = 1
merge_stdout_stderr = 1

module = Shell
shell_build_command = <<EOT
cd src
make clean IMB-MPI1
EOT

#----------------------------------------------------------------------

[Test build: netpipe]
test_get = netpipe
save_stdout_on_success = 1
merge_stdout_stderr = 1
stderr_save_lines = 100

module = Shell
shell_build_command = <<EOT
make mpi
EOT

#======================================================================
# Test Run phase
#======================================================================

[Test run: trivial]
test_build = trivial
pass = &and(&test_wifexited(), &eq(&test_wexitstatus(), 0))
skipped = 0
timeout = &max(10, &test_np())
save_stdout_on_pass = 1
merge_stdout_stderr = 1
stdout_save_lines = 100
stderr_save_lines = 100
np = &env_max_procs()

specify_module = Simple
simple_first:tests = &find_executables(".")

#----------------------------------------------------------------------

[Test run: intel]
test_build = intel
pass = &and(&test_wifexited(), &eq(&test_wexitstatus(), 0))
skipped = &and(&test_wifexited(), &eq(&test_wexitstatus(), 77))
timeout = &max(30, &multiply(10, &test_np()))
save_stdout_on_pass = 1
merge_stdout_stderr = 1
np = &min("60", &env_max_procs())

specify_module = Simple
simple_successful:tests = &find_executables("src")

simple_failures:tests = &find_executables("src/" . "&cat("supposed_to_fail")")
simple_failures:pass = &and(&test_wifexited(), &ne(&test_wexitstatus(), 0))
simple_failures:exclusive = 1
simple_failures:timeout = &env_max_procs()

# These tests sleep for 90 seconds (!) before attempting to process
# any messages
simple_really_slow:tests = src/MPI_Isend_flood_c src/MPI_Send_flood_c
simple_really_slow:pass = &and(&test_wifexited(), &eq(&test_wexitstatus(), 0))
simple_really_slow:exclusive = 1
simple_really_slow:timeout = &sum(120, &multiply(5, &test_np()))

# This test collectively sleeps for 26 seconds *per MCW rank*
simple_coll_slow:tests = src/MPI_collective_overlap_c
simple_coll_slow:pass = &and(&test_wifexited(), &eq(&test_wexitstatus(), 0))
simple_coll_slow:exclusive = 1
simple_coll_slow:timeout = &multiply(35, &test_np()))

#------------------------------------------------------------------------

[Test run: ibm]
test_build = ibm
pass = &and(&test_wifexited(), &eq(&test_wexitstatus(), 0))
skipped = &and(&test_wifexited(), &eq(&test_wexitstatus(), 77))
timeout = &max(30, &multiply(10, &test_np()))
save_stdout_on_pass = 1
merge_stdout_stderr = 1
np = &env_max_procs()

specify_module = Simple
simple_first:tests = &find_executables("collective", "communicator", \
                                       "datatype", "dynamic", "environment", \
                                       "group", "info", "pt2pt", "topology", \
                                       "onesided" )

simple_fail:tests = environment/abort environment/final
simple_fail:pass = &and(&test_wifexited(), &ne(&test_wexitstatus(), 0))
simple_fail:exclusive = 1
simple_fail:timeout = &env_max_procs()

spawns:tests  = dynamic/spawn dynamic/spawn_multiple
spawns:np = 2
spawns:pass = &and(&test_wifexited(), &ne(&test_wexitstatus(),0))
spawns:exclusive = 1
spawns:timeout = &multiply(5,&env_max_procs())

#----------------------------------------------------------------------

[Test run: onesided]
test_build = onesided
pass = &and(&test_wifexited(), &eq(&test_wexitstatus(), 0))
timeout = &max(30, &multiply(10, &test_np()))
save_stdout_on_pass = 1
merge_stdout_stderr = 1
stdout_save_lines = 100
np = &env_max_procs()

specify_module = Simple
simple_pass:tests = &cat("run_list")

#----------------------------------------------------------------------
     
[Test run: mpicxx]
test_build = mpicxx
pass = &and(&test_wifexited(), &eq(&test_wexitstatus(), 0))
timeout = &max(30, &multiply(10, &test_np()))
save_stdout_on_pass = 1
merge_stdout_stderr = 1
np = &env_max_procs()

specify_module = Simple
simple_pass:tests = src/mpi2c++_test

#----------------------------------------------------------------------

[Test run: imb correctness]
test_build = imb
pass = &eq(&test_exit_status(), 0)
timeout = &max(2800, &multiply(50, &test_np()))
save_stdout_on_pass = 1
merge_stdout_stderr = 1
np = &min("32", &env_max_procs())

specify_module = Simple
simple_first:tests = src/IMB-MPI1

#----------------------------------------------------------------------

[Test run: imb performance]
test_build = imb
pass = &eq(&test_wexitstatus(), 0)
timeout = -1
save_stdout_on_pass = 1
# Ensure to leave this value as "-1", or performance results could be lost!
stdout_save_lines = -1
merge_stdout_stderr = 1
np = &env_max_procs()

argv = -npmin &test_np() &enumerate("PingPong", "PingPing", "Sendrecv", "Exchange", "Allreduce", "Reduce", "Reduce_scatter", "Allgather", "Allgatherv", "Alltoall", "Bcast", "Barrier") 

specify_module = Simple
analyze_module = IMB
simple_pass:tests = IMB-MPI1

#----------------------------------------------------------------------

[Test run: netpipe]
test_build = netpipe
pass = &eq(&test_wexitstatus(), 0)
timeout = -1
save_stdout_on_pass = 1
# Ensure to leave this value as "-1", or performance results could be lost!
stdout_save_lines = -1
merge_stdout_stderr = 1
np = 2

specify_module = Simple
analyze_module = NetPipe
simple_pass:tests = NPmpi

#======================================================================
# Reporter phase
#======================================================================

[Reporter: text output]
module = TextFile

textfile_filename = $phase-$section-$mpi_name-$mpi_version.txt

textfile_summary_header = <<EOT
hostname: &shell("hostname")
uname: &shell("uname -a")
who am i: &shell("who am i")
EOT

textfile_summary_footer =
textfile_detail_header =
textfile_detail_footer =

textfile_textwrap = 78
